# Fairness Pipeline Configuration
# Complete end-to-end configuration for run_pipeline.py

# Data Configuration
data:
  path: 'data/sample_loan_data.csv'
  target_column: 'loan_approved'
  protected_attribute: 'gender'
  feature_columns: null  # null = auto-detect (all except target and protected)

# Bias Detection Configuration
bias_detection:
  protected_attribute: 'gender'
  
  # Reference distribution (expected demographic split)
  reference_distribution:
    0: 0.5  # Female: 50%
    1: 0.5  # Male: 50%
  
  # Which bias checks to run
  checks:
    - representation
    - proxy
    - statistical_disparity
  
  # Thresholds
  thresholds:
    representation: 0.2
    proxy_correlation: 0.5
    statistical_alpha: 0.05

# Bias Mitigation Configuration
bias_mitigation:
  # Method: 'reweighting', 'resampling', or 'none'
  method: 'reweighting'
  
  # Parameters for reweighting
  params:
    method: 'inverse_propensity'
    alpha: 1.0  # 1.0 = full reweighting, 0.0 = no reweighting

# Training Configuration
training:
  # Use fairness constraints during training
  use_fairness_constraints: false
  
  # If true, specify constraint type
  constraint_type: 'demographic_parity'  # or 'equalized_odds', 'equal_opportunity'
  eps: 0.05  # Constraint violation tolerance

# Fairness Metrics to Track
fairness_metrics:
  - demographic_parity
  - equalized_odds

# Fairness Threshold (maximum acceptable difference)
fairness_threshold: 0.1  # 10%

# Bootstrap Configuration (for measurement module)
bootstrap_samples: 1000
confidence_level: 0.95

# Monitoring Configuration
monitoring:
  enabled: true
  window_size: 1000
  drift_alpha: 0.05
  
  # Alert thresholds
  thresholds:
    demographic_parity: 0.1
    equalized_odds: 0.1

# MLflow Integration
mlflow:
  enabled: true
  experiment_name: 'fairness_pipeline'
  tracking_uri: null  # null = default (./mlruns)
  
# Reporting
reporting:
  generate_json: true
  generate_markdown: true
  output_dir: 'reports/'